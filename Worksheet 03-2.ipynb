{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial has been modified from meps-cqr.ipynb from conformal-prediction (https://github.com/aangelopoulos/conformal-prediction). It is based on Romano et al. (2019) (https://proceedings.neurips.cc/paper/2019/hash/5103c3584b063c431bd1268e9b5e76fb-Abstract.html). This worksheet in particular was created with the help of Claude 3.7.\n",
    "\n",
    "# Worksheet: Improved conditional coverage with *conformalized quantile regression* (CQR) using the Medical Expenditure Panel Survey (MEPS) data\n",
    "\n",
    "This tutorial explores how to apply conformal prediction techniques to quantile regression outputs using the Medical Expenditure Panel Survey (MEPS) data. The goal is to create prediction intervals that can adapt to different levels of noise with reliable coverage.\n",
    "\n",
    "### What is conformal prediction?\n",
    "\n",
    "Conformal prediction is a framework that allows us to construct prediction intervals with guaranteed coverage properties without making strong distributional assumptions. The key idea is to use a calibration dataset to determine how to adjust our predictions to achieve the desired coverage level.\n",
    "\n",
    "### What is quantile regression?\n",
    "\n",
    "Quantile regression estimates conditional quantiles of the response variable given the features. For a target quantile level $\\gamma$, we estimate the function $t_\\gamma(x)$ such that $\\mathbb{P}(Y ≤ t_\\gamma(x) | X = x) = \\gamma$. This is particularly useful for constructing prediction intervals, as we can use the lower and upper quantiles (e.g., $\\gamma = 0.1/2 = 0.05$ and $\\gamma = 1-0.1/2 = 0.95$for a 90% interval).\n",
    "\n",
    "### Conformalized quantile regression (CQR)\n",
    "\n",
    "Conformalized quantile regression (CQR) combines these ideas: we start with quantile regression estimates and then \"conformalize\" them to guarantee coverage. This approach maintains the adaptivity of quantile regression while providing the coverage guarantees of conformal prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install -U --no-cache-dir gdown --pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the MEPS Data\n",
    "\n",
    "We'll use the Medical Expenditure Panel Survey (MEPS) data, which contains information about healthcare expenditures. Our goal is to predict medical expenses (Y) based on various patient characteristics (X).\n",
    "\n",
    "The data includes:\n",
    "- X: Features related to patient demographics and health status\n",
    "- Y: Medical expenses (our target variable)\n",
    "- L: Lower quantile estimates from a pre-trained quantile regression model\n",
    "- U: Upper quantile estimates from the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cached data\n",
    "if not os.path.exists('../data'):\n",
    "    os.system('gdown 1h7S6N_Rx7gdfO3ZunzErZy6H7620EbZK -O ../data.tar.gz')\n",
    "    os.system('tar -xf ../data.tar.gz -C ../')\n",
    "    os.system('rm ../data.tar.gz')\n",
    "    \n",
    "data = np.load('../data/meps/meps-gbr.npz')\n",
    "X, Y, L, U = data['X'], data['y'], data['lower'], data['upper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the data dimensions\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"Y shape: {Y.shape}\")\n",
    "print(f\"L shape: {L.shape}\")\n",
    "print(f\"U shape: {U.shape}\")\n",
    "\n",
    "# Plot the distribution of medical expenses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Y, bins=50, alpha=0.7)\n",
    "plt.title('Distribution of Medical Expenses')\n",
    "plt.xlabel('Expenses ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the experiment\n",
    "\n",
    "We need to:\n",
    "1. Define the desired coverage level $1-α$\n",
    "2. Split our data into calibration and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 1: Set the target miscoverage rate alpha and calibration set size m\n",
    "alpha = # Your code here - target miscoverage rate (e.g., 0.1 for 90% coverage)\n",
    "m = # Your code here - number of calibration points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 2: Split the data into calibration and test sets\n",
    "# Create a boolean mask for selecting calibration points\n",
    "idx = # Your code here\n",
    "np.random.shuffle(idx)  # Shuffle to randomly select calibration points\n",
    "\n",
    "# Use the mask to split the data\n",
    "Y_cal, Y_te = # Your code here\n",
    "L_cal, L_te = # Your code here\n",
    "U_cal, U_te = # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformalized quantile regression (CQR)\n",
    "\n",
    "The CQR nonconformity score for an observation $(x,y)$ is:\n",
    "\n",
    "$$s(x,y) = \\max\\left\\{\\hat{t}_{\\alpha/2}(x)-y, y-\\hat{t}_{1-\\alpha/2}(x)\\right\\}$$\n",
    "\n",
    "**Think.** What is this nonconformity score capturing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 3: Calculate nonconformity scores for the calibration set\n",
    "S_cal = # Your code here\n",
    "\n",
    "# Sort the scores\n",
    "S_cal = np.sort(S_cal)\n",
    "\n",
    "# Calculate the conformity threshold (qhat)\n",
    "# This is the (1-alpha) quantile of the nonconformity scores\n",
    "qhat = # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing conformalized prediction intervals\n",
    "\n",
    "Now, we can construct our conformalized prediction intervals for the test set. The interval is:\n",
    "\n",
    "$$\\hat C(x) = [\\hat{t}_{\\alpha/2}(x) - \\hat{q}, \\hat{t}_{1-\\alpha/2}(x) + \\hat{q}],$$\n",
    "\n",
    "where $\\hat{q}$ is our conformity threshold (qhat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 4: Construct conformalized prediction intervals\n",
    "Chat = # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating coverage\n",
    "\n",
    "Let's check if our conformalized prediction intervals achieve the desired coverage. We'll also compare them with the original (non-conformalized) intervals $[\\hat{t}_{\\alpha/2}(x), \\hat{t}_{1-\\alpha/2}(x)]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 5: Calculate and compare empirical coverage\n",
    "# Coverage before conformalization\n",
    "empirical_coverage0 = # Your code here\n",
    "print(f\"The empirical coverage before conformalization is: {empirical_coverage0}\")\n",
    "\n",
    "# Coverage after conformalization\n",
    "empirical_coverage = # Your code here\n",
    "print(f\"The empirical coverage after conformalization is: {empirical_coverage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining conditional coverage\n",
    "\n",
    "One major advantage of conformalized prediction is improved conditional coverage across different subgroups. Let's check if our method achieves uniform coverage across different cancer diagnosis categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process cancer diagnosis variables\n",
    "X_cancer = X[~idx, 40:45]\n",
    "for col in range(X_cancer.shape[1]):\n",
    "    one_val = X_cancer[:, col].max()\n",
    "    X_cancer[:, col] = (X_cancer[:, col] == one_val).astype(int)\n",
    "cancer_dx = X_cancer.dot(np.arange(5)+1).astype(int)\n",
    "\n",
    "# Count observations in each cancer diagnosis category\n",
    "counts = [(cancer_dx == dx).sum() for dx in np.arange(5)+1]\n",
    "print(\"Number of observations per cancer diagnosis category:\")\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"Category {i+1}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 6: Calculate stratified coverage for each cancer diagnosis category\n",
    "# Coverage before conformalization\n",
    "stratified_coverage0 = # Your code here\n",
    "\n",
    "# Coverage after conformalization\n",
    "stratified_coverage = # Your code here\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(5)+1, stratified_coverage0, \"o\", label=\"Pre-conformalization\")\n",
    "plt.plot(np.arange(5)+1, stratified_coverage, \"o\", label=\"Post-conformalization\")\n",
    "plt.hlines(1-alpha, 0.5, 5.5, 'r', label=\"Target coverage\")\n",
    "plt.xlim(0.75, 5.25)\n",
    "plt.ylim(0.6, 1.0)\n",
    "plt.xlabel(\"Cancer Diagnosis Category\")\n",
    "plt.ylabel(\"Empirical Coverage\")\n",
    "plt.title(\"Coverage by Cancer Diagnosis Category\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key takeaways\n",
    "\n",
    "1. **The Coverage Problem**: Traditional quantile regression methods produce intervals that often don't achieve their target coverage in finite samples.\n",
    "\n",
    "2. **Conformal Prediction Solution**: By applying conformal prediction techniques to quantile regression outputs, we can guarantee the desired coverage level (1-α) without making distributional assumptions.\n",
    "\n",
    "3. **The CQR Procedure**:\n",
    "   - Start with estimated conditional quantiles from any quantile regression method\n",
    "   - Calculate nonconformity scores on a calibration set\n",
    "   - Adjust the original interval based on these scores\n",
    "\n",
    "4. **Empirical Results**:\n",
    "   - Pre-conformalization intervals achieved ~73% coverage when targeting 90%\n",
    "   - Post-conformalization intervals achieved ~93% coverage, meeting our target\n",
    "   - Coverage was more uniform across different subgroups after conformalization\n",
    "\n",
    "5. **Advantages**:\n",
    "   - Distribution-free coverage guarantees\n",
    "   - Can be applied on top of any existing quantile regression method\n",
    "   - Improves conditional coverage across different subpopulations\n",
    "\n",
    "6. **Limitations**:\n",
    "   - Requires a separate calibration set\n",
    "   - May produce wider intervals than uncalibrated methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion questions\n",
    "\n",
    "1. How does the conformalization process improve coverage compared to the original quantile regression intervals?\n",
    "\n",
    "2. How would you expect the width of the prediction intervals to change after conformalization? Why?\n",
    "\n",
    "3. What might explain any differences in coverage across the different cancer diagnosis categories?\n",
    "\n",
    "4. How might the choice of the base quantile regression model affect the final conformalized intervals?\n",
    "\n",
    "5. How would the choice of α affect our results? What tradeoffs are involved in selecting different values?\n",
    "\n",
    "6. How should we decide the size of the calibration set? What happens if it's too small or too large?\n",
    "\n",
    "7. How does CQR compare to other uncertainty quantification methods like bootstrap or Bayesian approaches?\n",
    "\n",
    "8. In what real-world scenarios would guaranteed coverage be particularly important when predicting medical expenses?\n",
    "\n",
    "9. How might conformal prediction help ensure fair treatment across different demographic groups?\n",
    "\n",
    "10. How would you explain the concept of conformalized prediction intervals to non-technical stakeholders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
